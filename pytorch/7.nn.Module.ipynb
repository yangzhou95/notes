{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# base class for all nural network modules,\n",
    "# UDF modules should inherit this class\n",
    "# allowing nest modules, a module includes other modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_module() missing 2 required positional arguments: 'name' and 'module'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/3706255838.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Adds a child module to the current module.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# The module can be accessed as an attribute using the given name.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mmy_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# Applies fn recursively to every submodule (as returned by\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: add_module() missing 2 required positional arguments: 'name' and 'module'"
     ]
    }
   ],
   "source": [
    "# add_module\n",
    "my_model = Model()\n",
    "# Adds a child module to the current module.\n",
    "# The module can be accessed as an attribute using the given name.\n",
    "my_model.add_module('name',module)\n",
    "\n",
    "# Applies fn recursively to every submodule (as returned by\n",
    "# .children()) as well as self. Typical use includes initializing\n",
    "# the parameters of a model (see also torch.nn.init).\n",
    "def fn(weights):\n",
    "    pass\n",
    "my_model.apply(fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "type: <class 'torch.nn.modules.container.Sequential'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=2, out_features=2, bias=True)\n  (1): Linear(in_features=2, out_features=2, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.fill_(1.0)\n",
    "        print(m.weight)\n",
    "    print('type:',type(m))\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "net.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1555, -0.1904,  0.1007, -0.1543,  0.0335],\n",
      "          [ 0.1126,  0.0402, -0.1774, -0.0415, -0.1666],\n",
      "          [-0.1572,  0.1696, -0.0159, -0.1752,  0.0927],\n",
      "          [ 0.0245, -0.0808, -0.0441,  0.1695,  0.0675],\n",
      "          [-0.1693, -0.1084,  0.1196,  0.1757, -0.1406]]],\n",
      "\n",
      "\n",
      "        [[[-0.0321, -0.0956, -0.1140, -0.0086, -0.0618],\n",
      "          [ 0.0343,  0.0722,  0.0246, -0.0106, -0.0427],\n",
      "          [-0.0138, -0.1679,  0.0410,  0.1437, -0.1461],\n",
      "          [ 0.1242,  0.0710,  0.1457,  0.1823,  0.0951],\n",
      "          [ 0.1734, -0.0379,  0.1789,  0.0467,  0.0278]]],\n",
      "\n",
      "\n",
      "        [[[-0.0385, -0.0345,  0.0564,  0.0888, -0.0266],\n",
      "          [ 0.1788,  0.0678, -0.0802,  0.1659,  0.0532],\n",
      "          [ 0.1465,  0.1191, -0.1121, -0.1802,  0.1661],\n",
      "          [-0.1589,  0.0829, -0.0032,  0.0950,  0.0521],\n",
      "          [-0.1870,  0.0664,  0.0513,  0.1224,  0.0263]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1451,  0.1351, -0.1409,  0.1106,  0.1012],\n",
      "          [-0.1257, -0.0584, -0.1194, -0.0503,  0.1520],\n",
      "          [-0.0153,  0.1717, -0.1386,  0.1833,  0.1698],\n",
      "          [ 0.1264, -0.0109,  0.0392,  0.0610,  0.1084],\n",
      "          [-0.0443, -0.1014,  0.1526, -0.0527, -0.0191]]],\n",
      "\n",
      "\n",
      "        [[[-0.1076,  0.1540,  0.0278, -0.1797,  0.0165],\n",
      "          [ 0.1160,  0.1548, -0.1974,  0.0383,  0.1386],\n",
      "          [ 0.1204, -0.1458, -0.0875, -0.1304, -0.0188],\n",
      "          [ 0.0371,  0.1735,  0.1232,  0.1681, -0.1067],\n",
      "          [-0.1551, -0.1620,  0.1601, -0.0655,  0.0610]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1510, -0.0868,  0.1370,  0.0667,  0.1194],\n",
      "          [-0.0562, -0.1929,  0.1368,  0.1813, -0.0091],\n",
      "          [-0.1507, -0.1438,  0.0345, -0.0013, -0.1243],\n",
      "          [-0.1041,  0.0537, -0.0846, -0.1298, -0.1232],\n",
      "          [ 0.1112, -0.1768,  0.1464,  0.0430,  0.1751]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0801, -0.0205, -0.1170, -0.0049, -0.1125],\n",
      "          [-0.0563, -0.0960,  0.0356,  0.1412,  0.0268],\n",
      "          [-0.0884,  0.1342,  0.1956,  0.1760,  0.1585],\n",
      "          [ 0.0877,  0.1705, -0.1896,  0.0079, -0.0809],\n",
      "          [ 0.1028,  0.1956, -0.1814,  0.0578, -0.0720]]],\n",
      "\n",
      "\n",
      "        [[[-0.1729, -0.0471, -0.0960,  0.0131,  0.0618],\n",
      "          [-0.1387,  0.0184, -0.1693,  0.0683, -0.1626],\n",
      "          [ 0.0206,  0.0404,  0.0530,  0.0361,  0.0128],\n",
      "          [ 0.0073, -0.0422,  0.1910,  0.0762, -0.1441],\n",
      "          [ 0.1114, -0.0768, -0.1305,  0.0545,  0.1635]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0024, -0.0552, -0.0841, -0.1614,  0.0697],\n",
      "          [-0.1070, -0.1508, -0.0179,  0.1208, -0.1402],\n",
      "          [-0.1577,  0.1973,  0.1329, -0.0156,  0.0099],\n",
      "          [-0.1860, -0.0276,  0.0826,  0.1390, -0.1727],\n",
      "          [ 0.1337,  0.1540, -0.0376,  0.0651, -0.1237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1595, -0.0926, -0.0450, -0.1708,  0.0184],\n",
      "          [-0.1020,  0.0063,  0.0751, -0.1729, -0.0138],\n",
      "          [ 0.0723, -0.1881,  0.0656, -0.1114,  0.0144],\n",
      "          [ 0.0083,  0.0491,  0.0144, -0.1246, -0.1002],\n",
      "          [ 0.1513,  0.1432, -0.1542, -0.1556, -0.0077]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149, -0.0601, -0.1453, -0.1356, -0.0334],\n",
      "          [ 0.0164, -0.1906,  0.1671, -0.1830, -0.0914],\n",
      "          [ 0.0070, -0.0711, -0.0440,  0.0828, -0.0878],\n",
      "          [ 0.1686,  0.0350,  0.0581,  0.0102,  0.1113],\n",
      "          [ 0.1130,  0.1787, -0.0347,  0.1230, -0.1903]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1628,  0.0530, -0.0148, -0.1662,  0.1141],\n",
      "          [-0.0312,  0.1726, -0.0645, -0.0090, -0.0752],\n",
      "          [-0.0463,  0.0561, -0.1729, -0.1382, -0.0864],\n",
      "          [-0.1525, -0.1108, -0.0985,  0.0881, -0.1292],\n",
      "          [-0.0283, -0.1381,  0.0043, -0.0380, -0.1479]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0830, -0.0607, -0.0572,  0.1530, -0.0049],\n",
      "          [-0.1086,  0.0695, -0.0156,  0.1883, -0.1442],\n",
      "          [ 0.0286,  0.1428, -0.1305,  0.0947,  0.1647],\n",
      "          [-0.0642, -0.0502,  0.1483, -0.1793, -0.1898],\n",
      "          [ 0.0861,  0.1376, -0.1438,  0.1262, -0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1154, -0.0297,  0.1161, -0.0245,  0.1510],\n",
      "          [ 0.0129, -0.1771,  0.0754, -0.0057, -0.0150],\n",
      "          [ 0.0491, -0.0415,  0.1729, -0.1383, -0.1245],\n",
      "          [ 0.1109,  0.1025,  0.0599,  0.1215,  0.1676],\n",
      "          [ 0.1037,  0.1888,  0.0942, -0.0514,  0.1026]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0695,  0.1837,  0.0088, -0.0401, -0.1039],\n",
      "          [ 0.0381,  0.1030,  0.0373,  0.0947,  0.1997],\n",
      "          [ 0.1817,  0.1595, -0.1318,  0.0295, -0.1345],\n",
      "          [ 0.0974,  0.0391, -0.0109, -0.0214,  0.1829],\n",
      "          [-0.0424, -0.1971,  0.0558,  0.0609, -0.1821]]],\n",
      "\n",
      "\n",
      "        [[[-0.1402, -0.1363,  0.1873,  0.1049,  0.0607],\n",
      "          [-0.0628, -0.1246,  0.0533,  0.0657, -0.1968],\n",
      "          [ 0.0817, -0.1805,  0.0280, -0.1569,  0.0718],\n",
      "          [ 0.0243,  0.0008,  0.0515, -0.1498, -0.1078],\n",
      "          [ 0.0513, -0.1361,  0.1533,  0.0349, -0.1247]]],\n",
      "\n",
      "\n",
      "        [[[-0.0280,  0.0029,  0.0489,  0.1926,  0.1987],\n",
      "          [ 0.1798,  0.1406, -0.0746,  0.1122,  0.1423],\n",
      "          [-0.1765, -0.0402,  0.1824, -0.0472, -0.1874],\n",
      "          [-0.1314, -0.1677, -0.0933,  0.0521, -0.1526],\n",
      "          [-0.1874, -0.0289, -0.0347,  0.0633,  0.0215]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1141,  0.1346, -0.0689, -0.1353,  0.1471],\n",
      "          [ 0.0715,  0.1863, -0.1920, -0.1344, -0.1421],\n",
      "          [-0.1179,  0.0343, -0.0104,  0.0516, -0.1434],\n",
      "          [ 0.0834,  0.0898, -0.1920, -0.0398,  0.1386],\n",
      "          [-0.1859, -0.0443,  0.0692,  0.0804, -0.1779]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1633, -0.0706, -0.1809, -0.0951, -0.0679],\n",
      "          [-0.1339, -0.1925, -0.0233,  0.1588,  0.0180],\n",
      "          [ 0.1765,  0.1359,  0.1894, -0.1172, -0.1294],\n",
      "          [ 0.1280, -0.1472, -0.0042,  0.1568,  0.0141],\n",
      "          [ 0.1865,  0.1760,  0.1310,  0.0399,  0.1986]]],\n",
      "\n",
      "\n",
      "        [[[-0.1298, -0.1009,  0.1539,  0.1217,  0.0156],\n",
      "          [ 0.1403, -0.0194, -0.1325, -0.1264,  0.0733],\n",
      "          [-0.0488,  0.0169,  0.0113, -0.1873, -0.1801],\n",
      "          [ 0.1721,  0.0531,  0.1214,  0.1450,  0.0408],\n",
      "          [ 0.0645, -0.1957, -0.1230, -0.1425,  0.0506]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1484, -0.1150,  0.0674,  0.1183, -0.0079,  0.0543, -0.1403,  0.1693,\n",
      "         0.1840, -0.0594,  0.0355,  0.0873, -0.1575, -0.1002, -0.0800,  0.1431,\n",
      "        -0.0497,  0.1327, -0.0645, -0.0686], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 5.1109e-03,  3.5041e-02, -7.5037e-03, -3.9770e-02,  3.8904e-02],\n",
      "          [-1.0358e-02, -1.3220e-02, -1.1123e-02,  2.7650e-02,  2.4495e-02],\n",
      "          [ 3.1014e-02, -2.8157e-02, -1.7184e-03,  3.4230e-02,  2.7204e-02],\n",
      "          [-1.1691e-02, -2.8821e-02, -3.7935e-02, -3.8237e-04,  3.1834e-02],\n",
      "          [ 1.4211e-02, -2.5826e-02, -1.1139e-05,  1.0216e-02,  3.4807e-02]],\n",
      "\n",
      "         [[-4.3019e-02, -4.0303e-02, -1.8622e-02, -8.9270e-03,  2.8309e-03],\n",
      "          [-3.1561e-03, -2.3060e-02, -1.5280e-02, -3.0346e-03,  2.2709e-02],\n",
      "          [ 2.1261e-02, -4.6849e-03, -2.8633e-02,  3.8974e-02, -1.9092e-02],\n",
      "          [ 3.0981e-02,  4.0428e-02, -6.5277e-03, -4.4700e-03, -3.5806e-02],\n",
      "          [-1.0842e-02, -6.5100e-03, -3.5606e-02, -4.0748e-02, -1.3474e-02]],\n",
      "\n",
      "         [[-5.6274e-03,  2.7119e-02, -2.2927e-02, -5.8473e-03,  1.7087e-02],\n",
      "          [-1.7932e-02,  4.4442e-02,  9.7975e-03,  2.8546e-02,  2.8696e-02],\n",
      "          [-1.5990e-02, -1.4691e-02, -3.5000e-02,  2.7392e-02, -2.0741e-02],\n",
      "          [-3.9036e-02,  1.4121e-02, -3.1748e-02,  1.6200e-02, -1.4180e-02],\n",
      "          [-2.2591e-02, -3.8615e-02, -2.4041e-02,  1.5422e-02, -8.2062e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1264e-02,  7.6601e-03,  1.8903e-02, -2.3504e-02,  1.9490e-03],\n",
      "          [ 2.6443e-02,  3.6174e-02,  2.7749e-02, -2.4779e-02, -7.8542e-03],\n",
      "          [-7.6646e-03,  1.3460e-02, -4.0182e-02,  3.0053e-02, -1.4649e-02],\n",
      "          [ 6.8923e-03, -1.5386e-02, -3.7294e-02,  1.3775e-02,  1.9943e-02],\n",
      "          [-3.8324e-02, -1.1738e-02, -1.5040e-02,  4.2484e-02, -1.0826e-02]],\n",
      "\n",
      "         [[-2.1897e-02,  2.9669e-02, -6.3844e-03, -3.5545e-02,  2.3038e-02],\n",
      "          [-2.5876e-02, -2.2349e-02, -4.1665e-02,  2.7378e-02,  1.6235e-02],\n",
      "          [-2.2517e-02, -2.5651e-02,  2.1315e-02,  2.6632e-03,  1.9581e-02],\n",
      "          [ 4.0461e-02,  1.3075e-02, -9.2377e-03, -1.6163e-02,  2.5568e-02],\n",
      "          [-2.0074e-02, -3.2974e-02,  1.2475e-04, -3.5391e-02,  4.1486e-02]],\n",
      "\n",
      "         [[ 1.1810e-02,  1.8480e-02, -3.9241e-02, -1.3118e-02,  3.0201e-02],\n",
      "          [-1.0874e-02, -3.0038e-02, -1.7950e-02,  2.2359e-05, -1.4472e-03],\n",
      "          [ 4.1647e-03,  2.1132e-02, -2.5494e-02, -2.4978e-02, -7.5899e-03],\n",
      "          [ 1.5631e-02,  6.4104e-03, -8.0743e-04,  3.2458e-02, -1.9027e-03],\n",
      "          [-1.9143e-02,  3.0224e-02,  1.4184e-02, -1.0237e-02,  2.7270e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0062e-02, -6.8883e-03,  3.4543e-02,  3.0835e-03,  2.9412e-02],\n",
      "          [ 2.2442e-02, -1.1994e-02,  2.1197e-02, -4.4628e-02,  1.9733e-02],\n",
      "          [-3.0670e-02,  3.0581e-02, -2.1601e-02, -1.0857e-03,  4.1030e-02],\n",
      "          [ 5.8088e-03,  3.7459e-02, -9.6811e-03,  1.9838e-02,  1.7519e-02],\n",
      "          [ 1.2518e-02,  4.1441e-02,  3.3830e-02,  2.8236e-02, -4.7026e-03]],\n",
      "\n",
      "         [[ 1.3120e-02,  3.0046e-02, -3.8259e-02, -2.5232e-02,  1.0420e-02],\n",
      "          [ 3.7894e-02, -2.2611e-03, -2.8825e-02, -1.6012e-02,  2.8948e-02],\n",
      "          [-3.9322e-02, -7.8709e-03, -3.2209e-02,  2.7142e-02, -4.4606e-02],\n",
      "          [ 3.8840e-02, -2.4033e-02,  1.1450e-02, -2.1937e-02,  2.5967e-03],\n",
      "          [ 2.8756e-02,  1.4613e-03, -4.1998e-02, -3.2164e-02, -2.7508e-02]],\n",
      "\n",
      "         [[-2.9605e-02, -2.9096e-02,  1.2943e-02, -1.2259e-03,  2.8145e-02],\n",
      "          [ 1.9916e-02, -2.1545e-02,  2.3708e-02, -1.1989e-02, -2.3435e-02],\n",
      "          [-3.8730e-02,  1.4583e-02, -1.1871e-02, -4.2009e-02,  7.8623e-03],\n",
      "          [ 3.9602e-02,  2.9025e-02, -3.4331e-02, -4.4341e-03, -2.7037e-02],\n",
      "          [-1.8509e-02, -5.8375e-03,  9.8197e-03, -3.8530e-02,  3.1593e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4562e-02, -1.1423e-03, -3.5944e-02,  2.5367e-02,  3.5620e-02],\n",
      "          [-4.4588e-03,  4.9549e-03, -1.1377e-02, -2.1167e-02,  4.1802e-02],\n",
      "          [-1.2860e-02, -7.1248e-03,  3.6991e-02,  4.2713e-02, -2.4286e-02],\n",
      "          [-1.3525e-02, -3.1660e-02,  1.3649e-02, -3.6323e-02,  4.2552e-02],\n",
      "          [-1.9610e-02,  1.1985e-02,  8.3498e-04,  2.9217e-02,  4.0361e-02]],\n",
      "\n",
      "         [[-3.6590e-02, -3.1575e-02,  2.9705e-03, -1.4081e-03, -3.2273e-02],\n",
      "          [-4.2736e-02, -1.5144e-03, -2.6273e-02, -4.0238e-02, -9.7527e-03],\n",
      "          [ 2.3513e-02,  3.3647e-02,  2.1473e-02, -1.2059e-02,  1.8064e-02],\n",
      "          [-1.2165e-02,  4.0204e-02,  2.3270e-02, -2.4520e-02, -8.5099e-03],\n",
      "          [-3.1247e-03,  1.7658e-02, -1.8225e-02,  1.4150e-02,  2.9067e-02]],\n",
      "\n",
      "         [[-1.0115e-02, -1.9575e-03, -6.1602e-04, -2.3823e-02, -2.8033e-02],\n",
      "          [ 2.3539e-02,  7.8882e-03, -4.4630e-02, -2.9096e-02,  4.2276e-02],\n",
      "          [-8.3102e-03, -4.1560e-02, -3.1986e-02, -3.9719e-02, -2.9566e-02],\n",
      "          [ 1.8051e-02, -3.4852e-02, -3.6180e-02, -2.5842e-02, -4.0716e-02],\n",
      "          [ 2.4548e-02,  2.2638e-02, -2.1265e-02,  4.1628e-02, -2.4403e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8332e-02,  1.1721e-02, -4.2728e-03,  2.4389e-02, -1.2588e-02],\n",
      "          [ 3.1580e-02, -4.1818e-02,  3.4339e-02,  3.3814e-02, -2.7805e-02],\n",
      "          [-1.2939e-02,  4.3958e-02, -2.6370e-02,  1.2579e-02,  3.4916e-02],\n",
      "          [-3.4003e-02, -2.6952e-02, -2.0427e-02,  4.1300e-04,  3.4241e-04],\n",
      "          [ 1.0160e-02, -7.4709e-03, -2.9094e-02,  5.3860e-03, -3.1181e-02]],\n",
      "\n",
      "         [[ 3.3969e-02,  7.8696e-03,  2.8632e-02, -2.0192e-02, -1.9110e-02],\n",
      "          [-1.0504e-02,  3.8836e-02,  3.1686e-02, -3.9655e-02,  9.6714e-03],\n",
      "          [ 2.6703e-02,  3.3292e-03, -3.5754e-03, -9.5923e-03,  4.2210e-02],\n",
      "          [ 3.3628e-02,  1.7119e-02,  6.0611e-03, -2.2058e-02,  3.5232e-02],\n",
      "          [-1.7566e-02, -2.6142e-03,  3.1124e-02, -4.2854e-02, -1.9382e-02]],\n",
      "\n",
      "         [[-1.9543e-02, -3.5846e-02, -3.3270e-02,  3.3568e-02, -1.0975e-02],\n",
      "          [ 1.3384e-04,  8.6359e-03, -1.0988e-02, -4.0099e-02,  2.1617e-02],\n",
      "          [-2.7738e-02, -1.5149e-02, -1.2177e-02, -3.8818e-02, -3.7908e-02],\n",
      "          [ 9.1582e-03,  2.3556e-02,  5.8862e-03,  1.9259e-02, -1.8922e-03],\n",
      "          [ 1.5188e-02,  7.8184e-03,  4.3726e-02, -2.4107e-02, -1.8062e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8121e-02,  1.2534e-02, -6.6719e-03,  8.8830e-03,  7.7616e-03],\n",
      "          [-2.0851e-02,  2.9774e-02, -1.4661e-02,  1.2172e-02, -3.1911e-02],\n",
      "          [ 2.9617e-02, -1.9773e-02,  4.0376e-02, -2.6122e-02, -2.2993e-02],\n",
      "          [-3.7040e-02,  2.2674e-02,  1.2830e-02,  3.9358e-02, -1.4381e-02],\n",
      "          [-3.5026e-02, -2.1171e-02,  4.0543e-02, -3.3712e-02,  2.0167e-02]],\n",
      "\n",
      "         [[-3.4703e-02,  1.7513e-02, -4.4129e-02, -3.6099e-02,  1.6651e-02],\n",
      "          [-2.9925e-04,  7.6001e-03,  4.3580e-02, -2.9010e-02, -7.7358e-03],\n",
      "          [-3.8462e-02,  2.7533e-03,  1.7538e-02,  2.7973e-02, -4.0921e-02],\n",
      "          [-3.1050e-02,  3.6829e-02,  3.4596e-02, -3.3199e-02, -2.2322e-02],\n",
      "          [ 1.7657e-03,  2.9345e-03, -1.9143e-02, -2.9332e-02, -3.3166e-02]],\n",
      "\n",
      "         [[ 3.7591e-02, -3.9572e-02,  3.5332e-02,  3.5172e-02,  3.3931e-02],\n",
      "          [-3.6461e-02, -1.2178e-02, -1.9007e-02,  4.1497e-02,  7.5217e-03],\n",
      "          [-3.3971e-02, -4.2004e-02,  2.6967e-02, -8.4460e-03, -1.4235e-03],\n",
      "          [ 8.5054e-03,  5.7138e-03, -2.7104e-02,  7.5520e-03, -4.0212e-02],\n",
      "          [ 5.2987e-03,  2.1233e-02,  3.7305e-02, -3.0905e-02,  2.0777e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4310e-02, -1.8009e-02, -7.5224e-03,  3.9099e-02, -3.1347e-02],\n",
      "          [ 4.3899e-02,  2.7067e-02, -2.7568e-02, -3.8062e-03, -3.8749e-03],\n",
      "          [ 7.2517e-03, -3.8798e-02, -1.8446e-02,  1.8958e-02,  2.8805e-02],\n",
      "          [ 1.5320e-03, -2.2952e-02, -7.6848e-04, -3.9243e-02, -3.9021e-03],\n",
      "          [-4.3772e-03,  1.2072e-02, -7.4761e-03,  2.0605e-03,  3.0749e-04]],\n",
      "\n",
      "         [[-4.1941e-02, -1.7530e-02,  1.9418e-02, -3.1526e-02,  5.9680e-03],\n",
      "          [ 1.5210e-02, -1.2930e-03, -2.4799e-02, -3.8688e-02, -1.7361e-02],\n",
      "          [-1.5619e-02,  1.5502e-02, -2.9030e-02,  2.4336e-02,  3.2408e-02],\n",
      "          [-1.7260e-02,  2.2688e-02,  1.1599e-03,  5.2066e-03, -3.4822e-02],\n",
      "          [ 7.8545e-03,  3.4541e-02,  2.5396e-02, -8.8257e-04,  2.8430e-02]],\n",
      "\n",
      "         [[ 4.4074e-02, -3.7748e-02,  2.8767e-02, -4.2641e-02,  2.5995e-02],\n",
      "          [ 3.4187e-02,  1.5199e-03, -1.9519e-02, -3.5905e-02, -3.2247e-02],\n",
      "          [-3.5088e-02,  3.6361e-03,  4.5073e-03, -3.0859e-02, -2.4913e-02],\n",
      "          [-8.6311e-03, -1.5040e-02, -1.8526e-02, -4.0777e-02,  2.4844e-02],\n",
      "          [-2.0698e-02,  5.0158e-03,  2.4298e-02,  2.6131e-02,  4.1296e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0597e-04, -2.4710e-02, -4.4237e-02, -2.5419e-02,  2.5393e-02],\n",
      "          [ 1.9759e-02, -2.8093e-02,  3.3054e-02, -3.6489e-02, -1.0054e-02],\n",
      "          [-1.7686e-02, -9.1916e-04, -1.9177e-02, -3.4434e-02, -3.3390e-02],\n",
      "          [ 2.3981e-02,  1.3170e-03, -2.2917e-02, -4.0399e-02, -3.3162e-02],\n",
      "          [-4.4329e-02,  6.9305e-03,  2.5946e-02, -1.9425e-02,  1.5708e-02]],\n",
      "\n",
      "         [[-9.5020e-03, -3.7135e-02,  3.5378e-02, -3.6060e-02,  4.4339e-02],\n",
      "          [-4.4301e-02,  3.3484e-03,  2.1045e-02, -4.2894e-02, -4.3985e-02],\n",
      "          [-1.5654e-02,  3.4082e-02,  1.5171e-02,  2.4768e-02, -1.1800e-02],\n",
      "          [-2.7810e-02, -1.0545e-03,  1.0707e-03,  1.1485e-02, -2.8580e-02],\n",
      "          [ 2.9274e-02, -3.9018e-02,  3.1078e-03,  4.0633e-02,  4.6676e-04]],\n",
      "\n",
      "         [[-3.2591e-02,  4.2368e-02, -6.3739e-03,  2.2107e-03, -4.1654e-02],\n",
      "          [-4.4226e-02,  2.1104e-02,  3.8607e-02,  3.6669e-02, -2.7009e-02],\n",
      "          [ 4.3139e-02,  3.2113e-02, -1.1249e-03, -1.3256e-02,  2.7483e-02],\n",
      "          [-4.0687e-02, -4.3006e-02,  3.1046e-03, -2.7478e-02, -5.0371e-03],\n",
      "          [ 3.6637e-02, -1.4822e-02, -3.2639e-02, -1.8060e-02,  3.8205e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6370e-03,  1.8458e-02,  2.0457e-02, -4.3817e-02, -2.6452e-02],\n",
      "          [-8.7671e-03, -1.6688e-02, -2.0910e-02, -4.2946e-02,  1.5368e-02],\n",
      "          [ 1.3428e-02, -2.1339e-02, -4.3264e-02, -2.2913e-02, -3.9696e-03],\n",
      "          [-1.4682e-02,  2.2295e-02,  2.7466e-03,  1.5543e-02, -1.3880e-02],\n",
      "          [-4.2936e-02,  1.9554e-02,  3.8210e-02,  3.7011e-02,  3.3251e-02]],\n",
      "\n",
      "         [[-3.3433e-02, -4.3266e-02, -3.2246e-02,  1.8361e-02,  3.4272e-02],\n",
      "          [ 3.9720e-02,  3.4184e-02, -2.0790e-02, -1.0311e-02,  2.2824e-02],\n",
      "          [ 3.6694e-02,  1.0182e-02,  1.7696e-02, -3.8881e-02,  2.2104e-02],\n",
      "          [ 4.2920e-02, -7.0497e-03, -7.4677e-03,  4.1039e-02, -1.4812e-03],\n",
      "          [-3.6750e-02, -4.2768e-02, -3.5805e-02, -4.0971e-02,  2.4903e-02]],\n",
      "\n",
      "         [[-4.0041e-02,  2.7863e-03, -3.7486e-02, -1.5345e-02, -2.3630e-02],\n",
      "          [ 2.2868e-02, -1.0777e-02,  2.1111e-02,  1.5660e-02, -6.2499e-03],\n",
      "          [-2.9909e-02, -1.4463e-03,  1.2511e-02, -2.6313e-02, -3.8937e-02],\n",
      "          [-3.8111e-02,  3.4467e-02,  3.9769e-02,  3.2377e-02, -2.5397e-04],\n",
      "          [-8.4658e-03, -3.2833e-02,  1.0608e-02,  2.0792e-02,  2.5390e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1177e-02,  1.7606e-02, -4.9072e-03, -3.4549e-02, -1.6445e-02],\n",
      "          [-2.4416e-02, -1.5710e-02, -3.8455e-02,  1.1093e-02,  2.7574e-02],\n",
      "          [-3.8376e-03, -3.3474e-02,  1.8739e-02, -1.1470e-02, -1.7684e-02],\n",
      "          [ 3.7921e-03, -1.8144e-02, -4.2374e-02, -6.3676e-03,  3.2765e-02],\n",
      "          [-5.3075e-03, -3.0696e-02, -1.0079e-03, -2.1328e-02, -4.2730e-02]],\n",
      "\n",
      "         [[-6.4436e-03, -2.8799e-02,  1.1871e-02, -2.9689e-02,  3.1842e-02],\n",
      "          [-3.0935e-02,  1.3981e-02,  3.7693e-02,  4.1659e-02, -1.5361e-02],\n",
      "          [ 3.9520e-02, -4.1621e-02, -7.5058e-04,  3.2115e-02, -4.1769e-03],\n",
      "          [-3.4714e-02, -3.9539e-03, -1.6497e-02, -2.5436e-02,  3.3146e-02],\n",
      "          [-1.1857e-02, -1.3787e-02, -1.8645e-02,  4.2511e-02, -2.4027e-02]],\n",
      "\n",
      "         [[ 4.3681e-02,  1.4376e-02, -1.8477e-02,  3.3187e-02, -4.2603e-02],\n",
      "          [-2.2205e-02,  1.4554e-02,  2.8897e-02,  4.1792e-02,  6.6488e-03],\n",
      "          [ 1.6102e-02,  2.1840e-02,  3.4706e-02,  3.8428e-02, -2.8764e-02],\n",
      "          [-3.1573e-02, -4.0701e-02,  2.0678e-02, -3.2240e-02,  4.0744e-02],\n",
      "          [ 5.9668e-03, -3.7092e-02, -2.4424e-02,  1.9628e-02, -1.5400e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1404e-02, -3.6060e-02, -3.4174e-02, -2.0859e-02,  3.1660e-02],\n",
      "          [-8.1313e-03,  3.2700e-02,  3.5996e-02, -2.6759e-02, -2.9409e-02],\n",
      "          [-1.8617e-02,  3.5182e-02,  2.1697e-03,  3.0999e-02, -1.8090e-02],\n",
      "          [ 6.8840e-03,  3.9779e-02,  1.0871e-02, -4.1731e-02,  1.1073e-02],\n",
      "          [ 4.2997e-02, -2.8059e-02,  1.0860e-02, -2.1077e-02,  1.7092e-03]],\n",
      "\n",
      "         [[ 1.6072e-02, -9.2815e-03,  8.3599e-03, -3.0902e-02,  3.5165e-02],\n",
      "          [ 2.9399e-02,  1.2328e-02,  4.2213e-02, -1.2039e-02, -1.3687e-02],\n",
      "          [ 2.2334e-02,  3.9714e-02,  3.8159e-02, -1.4967e-02, -4.2377e-02],\n",
      "          [ 4.2607e-02,  3.9682e-02,  2.6315e-02,  2.5422e-02, -1.1946e-02],\n",
      "          [ 1.2040e-02,  2.2913e-02,  2.3885e-02,  4.2899e-02,  3.4981e-02]],\n",
      "\n",
      "         [[-2.1087e-02,  5.1306e-03,  2.3635e-02, -2.7722e-02,  4.4406e-02],\n",
      "          [ 2.7918e-02, -1.3804e-02,  6.0538e-03, -2.7166e-04, -7.1303e-03],\n",
      "          [-3.1982e-04,  4.0776e-02, -3.4409e-02, -4.0864e-02,  1.8862e-02],\n",
      "          [-2.3141e-02, -7.8557e-03,  5.8371e-04, -7.7196e-03,  4.1699e-02],\n",
      "          [ 2.8128e-02,  2.0002e-02,  3.2621e-02,  1.4273e-02,  2.0737e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5837e-02, -2.5021e-02, -2.6325e-02, -1.5804e-02, -1.0221e-02],\n",
      "          [-5.3769e-03, -5.4749e-03,  2.0638e-02, -1.5949e-02, -1.4834e-03],\n",
      "          [ 2.5598e-03, -3.3515e-02,  4.3427e-02,  4.0601e-02, -4.3084e-03],\n",
      "          [-1.2343e-02,  3.0252e-02, -4.0234e-02, -1.0265e-02,  1.4342e-02],\n",
      "          [-3.4810e-02, -5.0115e-03, -2.5680e-03, -3.1574e-02,  2.2571e-02]],\n",
      "\n",
      "         [[-2.8432e-02,  1.9815e-02, -2.1725e-02,  1.0115e-02,  2.5983e-02],\n",
      "          [ 5.4958e-03, -4.4515e-02, -2.6174e-02, -2.8541e-02, -4.1549e-02],\n",
      "          [-3.8580e-02,  4.0845e-02,  2.1945e-02,  2.8200e-02,  4.2855e-02],\n",
      "          [-3.2513e-02,  3.2364e-02,  6.2839e-04, -2.5549e-02, -3.2975e-02],\n",
      "          [ 4.0330e-04,  3.2089e-02, -1.2336e-02,  2.6570e-02,  4.0093e-03]],\n",
      "\n",
      "         [[-1.8098e-02,  4.4849e-03, -1.4259e-02, -1.7753e-02,  3.9877e-02],\n",
      "          [-1.6409e-02, -2.9340e-02,  4.2508e-02,  1.2350e-02,  4.3844e-03],\n",
      "          [-1.2668e-02, -3.6459e-02,  2.4081e-02, -3.8952e-02,  4.1191e-02],\n",
      "          [-3.7829e-02, -1.0539e-02, -2.8179e-02, -1.0874e-02, -3.6924e-02],\n",
      "          [-4.1453e-02,  3.7387e-02, -3.7176e-02,  2.5186e-02, -8.3084e-03]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0394, -0.0216, -0.0117, -0.0150, -0.0170, -0.0412, -0.0377,  0.0312,\n",
      "         0.0354, -0.0279,  0.0417,  0.0058,  0.0141,  0.0002,  0.0249,  0.0105,\n",
      "        -0.0045, -0.0413,  0.0141, -0.0199], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# parameter vs buffer\n",
    "# parameter: calculate gradient\n",
    "# buffer: do not compute gradient\n",
    "for buf in my_model.buffers():\n",
    "    print(type(buf), buf.size())\n",
    "\n",
    "for param in my_model.parameters():\n",
    "    print(param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "net.children()#Returns an iterator over immediate children modules.\n",
    "# This method modifies the module in-place.\n",
    "net.cpu()# Moves all model parameters and buffers to the CPU.\n",
    "\n",
    "# Moves all model parameters and buffers to the GPU.\n",
    "# This also makes associated parameters and buffers different objects.\n",
    "# So it should be called before constructing optimizer if the module\n",
    "# will live on GPU while being optimized.\n",
    "net.cuda()\n",
    "\n",
    "# Sets the module in evaluation mode. This has any effect only on\n",
    "# certain modules. It has special effects on Dropout, BatchNorm, etc.\n",
    "net.eval()\n",
    "\n",
    "# Returns any extra state to include in the moduleâ€™s state_dict.\n",
    "# Implement this and a corresponding set_extra_state().param: target\n",
    "target = \"target_str\"\n",
    "net.get_extra_state(target)\n",
    "\n",
    "\n",
    "# Returns the parameter given by target if it exists, otherwise throws an error.\n",
    "\n",
    "net.get_parameter(target)\n",
    "\n",
    "# Returns the submodule given by target if it exists, otherwise throws an error.\n",
    "# assume you hav model: A.net_b.net_c.linear, to  To check whether or not we have\n",
    "# the ``linear`` submodule, we would call ``get_submodule(\"net_b.linear\")``\n",
    "net.get_submodule(target)\n",
    "\n",
    "# Copies parameters and buffers from state_dict into this module and its descendants\n",
    "# state_dict includes parameters and buffers\n",
    "net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Returns an iterator over all modules in the network. Duplicate modules are returned only once.\n",
    "net.modules()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "net = Net()\n",
    "# Additional information\n",
    "EPOCH = 5\n",
    "PATH = \"model.pt\"\n",
    "LOSS = 0.4\n",
    "\n",
    "torch.save({\n",
    "    'epoch': EPOCH,\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': LOSS,\n",
    "}, PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_34315/1941552234.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model_state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'optimizer_state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'epoch'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf150/lib/python3.7/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mload_state_dict\u001B[0;34m(self, state_dict)\u001B[0m\n\u001B[1;32m    143\u001B[0m         \u001B[0msaved_lens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mg\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'params'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msaved_groups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp_len\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0ms_len\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms_len\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam_lens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msaved_lens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001B[0m\u001B[1;32m    146\u001B[0m                              \"that doesn't match the size of optimizer's group\")\n\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# persistent = False, will not save, will not be a part of model's state_dict\n",
    "# BatchNorm's ``running_mean`` is not a parameter\n",
    "net.register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True)\n",
    "\n",
    "# Parameter() is a subclass of Tensor, when Parameter is assigned as a module attribute,\n",
    "# it will be auto added to the module's parameters, and appear in the iterator parameters()\n",
    "# assigning a Tensor doesn't have such effect\n",
    "net.register_parameter(self, name: str, param: Optional[Parameter])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GaussianModel, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(1))\n",
    "        self.pdf = torch.distributions.Normal(self.mean, torch.tensor([1.0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return -self.pdf.log_prob(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0593,  0.0321, -0.0535,  0.0566, -0.0247],\n",
      "          [ 0.0888,  0.0446, -0.0138,  0.0342,  0.0201],\n",
      "          [-0.0408, -0.0749,  0.0199,  0.0353, -0.0504],\n",
      "          [ 0.0173, -0.0933,  0.0903, -0.0871, -0.0575],\n",
      "          [-0.0078, -0.1075,  0.0182,  0.0307,  0.0190]],\n",
      "\n",
      "         [[ 0.0701, -0.0358,  0.0921,  0.0858,  0.0576],\n",
      "          [ 0.1066,  0.0422, -0.1078,  0.0685,  0.1135],\n",
      "          [-0.0934, -0.1065, -0.0767, -0.0419,  0.0700],\n",
      "          [ 0.0784, -0.0037, -0.0501,  0.0086,  0.0525],\n",
      "          [-0.0982,  0.0219, -0.0296,  0.0480, -0.0190]],\n",
      "\n",
      "         [[ 0.0539,  0.0367,  0.1011, -0.0142, -0.0594],\n",
      "          [ 0.0981, -0.1098,  0.0092, -0.0434,  0.1091],\n",
      "          [ 0.0173,  0.0519,  0.0058, -0.0810, -0.0487],\n",
      "          [ 0.0246, -0.0755,  0.1066,  0.0008,  0.0584],\n",
      "          [-0.0262,  0.0325, -0.1141, -0.1060, -0.0720]]],\n",
      "\n",
      "\n",
      "        [[[-0.0279,  0.0727,  0.0918, -0.0543, -0.0699],\n",
      "          [-0.0298,  0.0843, -0.0487,  0.0128, -0.0811],\n",
      "          [-0.0792, -0.0897,  0.0819,  0.0590, -0.1099],\n",
      "          [ 0.0247,  0.0471, -0.1051, -0.0355, -0.1050],\n",
      "          [ 0.0204,  0.0250, -0.1112, -0.0425, -0.0976]],\n",
      "\n",
      "         [[ 0.0967, -0.0569, -0.0621, -0.0788,  0.0492],\n",
      "          [ 0.1022, -0.0600,  0.0051, -0.0420, -0.0682],\n",
      "          [-0.0574, -0.0222, -0.0535, -0.1104,  0.0588],\n",
      "          [ 0.1074,  0.1043,  0.0930,  0.0776,  0.0427],\n",
      "          [-0.0865, -0.0150, -0.0778,  0.0744, -0.1087]],\n",
      "\n",
      "         [[-0.0921, -0.0336,  0.0445, -0.0820, -0.0594],\n",
      "          [ 0.1077, -0.0843, -0.0113, -0.0158,  0.0605],\n",
      "          [ 0.0647, -0.0186,  0.0353,  0.0960,  0.0543],\n",
      "          [ 0.1125,  0.0773, -0.0349, -0.0519,  0.0900],\n",
      "          [ 0.0234, -0.0427,  0.0747,  0.0060,  0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.0235, -0.0541,  0.0545,  0.0284],\n",
      "          [ 0.0447,  0.0119,  0.0822, -0.0899,  0.0792],\n",
      "          [-0.0074,  0.0405,  0.1154, -0.0281, -0.0561],\n",
      "          [ 0.1073,  0.1136, -0.0375,  0.0148, -0.0188],\n",
      "          [-0.0937,  0.0990, -0.1039, -0.0896, -0.0877]],\n",
      "\n",
      "         [[ 0.0668, -0.0136, -0.0360,  0.0511, -0.0289],\n",
      "          [-0.0034, -0.0880,  0.0036, -0.0470, -0.0732],\n",
      "          [-0.1058, -0.0779,  0.0375, -0.0195, -0.0423],\n",
      "          [-0.0712, -0.0311,  0.0240, -0.0074,  0.0823],\n",
      "          [ 0.0151, -0.0189,  0.0737,  0.0902,  0.0752]],\n",
      "\n",
      "         [[-0.0066, -0.0173, -0.0921,  0.0633, -0.0067],\n",
      "          [-0.0237, -0.0179,  0.0801,  0.0898, -0.0838],\n",
      "          [ 0.0715, -0.1030, -0.0646, -0.0926, -0.0618],\n",
      "          [-0.0816, -0.0144,  0.0277, -0.0430,  0.1102],\n",
      "          [-0.0641, -0.0779, -0.0498, -0.0216, -0.0231]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0803, -0.1116,  0.0760, -0.0756, -0.0618],\n",
      "          [-0.0789,  0.0027, -0.0134,  0.0556, -0.1135],\n",
      "          [-0.0935,  0.0036,  0.0950,  0.1130, -0.1136],\n",
      "          [ 0.0096, -0.0764, -0.0804,  0.0775,  0.1121],\n",
      "          [-0.1086,  0.1076,  0.0351, -0.0961, -0.0746]],\n",
      "\n",
      "         [[ 0.0812, -0.0419, -0.0568, -0.0382, -0.0588],\n",
      "          [-0.0512, -0.0357, -0.0142,  0.0284,  0.0388],\n",
      "          [ 0.0331,  0.1154, -0.0995, -0.0434, -0.0967],\n",
      "          [-0.0143, -0.0691, -0.0235, -0.0928,  0.0475],\n",
      "          [ 0.1032, -0.0833,  0.0788, -0.0977,  0.0251]],\n",
      "\n",
      "         [[-0.1054,  0.1121,  0.0871,  0.0494,  0.0288],\n",
      "          [ 0.1062, -0.0884, -0.0694,  0.0293, -0.0807],\n",
      "          [ 0.1070,  0.1114,  0.1012, -0.0009, -0.0914],\n",
      "          [-0.0887,  0.0213,  0.0017, -0.0557,  0.0914],\n",
      "          [ 0.0675, -0.0447,  0.0732,  0.0241, -0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0668,  0.0707, -0.0701,  0.0311],\n",
      "          [-0.0540,  0.0358, -0.0289,  0.0762, -0.0717],\n",
      "          [-0.1074,  0.0389,  0.0544,  0.1036, -0.0740],\n",
      "          [ 0.0502, -0.0131,  0.0606,  0.0182,  0.0542],\n",
      "          [ 0.1120, -0.1087, -0.0171,  0.0573, -0.0906]],\n",
      "\n",
      "         [[-0.0340, -0.0396, -0.0420, -0.0653,  0.1117],\n",
      "          [-0.0361,  0.0693, -0.0419, -0.0647,  0.0841],\n",
      "          [-0.0132, -0.0877,  0.0270, -0.1023, -0.0770],\n",
      "          [ 0.0604,  0.0770, -0.1081,  0.0476, -0.0538],\n",
      "          [ 0.0711,  0.0312,  0.1040, -0.0255, -0.0420]],\n",
      "\n",
      "         [[-0.0343, -0.0905, -0.0230, -0.0891,  0.0304],\n",
      "          [ 0.0283,  0.0603,  0.0683,  0.0150, -0.0687],\n",
      "          [ 0.0461,  0.0354,  0.0591,  0.0496, -0.0258],\n",
      "          [ 0.1066,  0.0175, -0.0290,  0.1127, -0.0851],\n",
      "          [ 0.0516, -0.0145,  0.0760,  0.0232,  0.1025]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0405,  0.0643, -0.0452,  0.0394, -0.0836],\n",
      "          [ 0.0246,  0.0297,  0.0752, -0.0594,  0.0493],\n",
      "          [ 0.0717, -0.0929,  0.0774, -0.0420, -0.0409],\n",
      "          [-0.0864, -0.0605, -0.1125, -0.1110,  0.0506],\n",
      "          [ 0.0691,  0.0209,  0.0448,  0.0868,  0.0597]],\n",
      "\n",
      "         [[-0.0699, -0.1052, -0.1022,  0.1031, -0.0483],\n",
      "          [-0.0082,  0.0138,  0.0890,  0.0780, -0.0381],\n",
      "          [ 0.0417, -0.1127, -0.0837,  0.0589, -0.0924],\n",
      "          [ 0.0473,  0.0484, -0.1045,  0.1120, -0.0427],\n",
      "          [ 0.0306,  0.0492, -0.0378, -0.1045,  0.0102]],\n",
      "\n",
      "         [[-0.0970,  0.0808, -0.1058,  0.0493, -0.0120],\n",
      "          [ 0.0027, -0.0234,  0.0985,  0.0823, -0.0329],\n",
      "          [ 0.0810,  0.0950, -0.1068,  0.0668,  0.1043],\n",
      "          [-0.0147, -0.0472, -0.0121, -0.0147, -0.0567],\n",
      "          [-0.0890, -0.0495, -0.0657,  0.0131,  0.1139]]]], requires_grad=True)\n",
      "type: <class 'torch.nn.parameter.Parameter'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_has_compatible_shallow_copy_type(): argument 'from' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_34315/88348670.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# apply fn on all Parameters (._parameters) and Buffers (._buffers).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minit_weights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Casts all parameters and buffers to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf150/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    528\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf150/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    551\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m                     \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m                 \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m                     \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf150/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mcompute_should_use_set_data\u001B[0;34m(tensor, tensor_applied)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 533\u001B[0;31m             \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_has_compatible_shallow_copy_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    534\u001B[0m                 \u001B[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    535\u001B[0m                 \u001B[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: _has_compatible_shallow_copy_type(): argument 'from' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "# apply fn on all Parameters (._parameters) and Buffers (._buffers).\n",
    "net._apply(init_weights)\n",
    "net.cuda()\n",
    "\n",
    "# Casts all parameters and buffers to\n",
    "net.type()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## part 8 - save checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/zhou/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "15.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "24.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "29.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "36.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "43.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "50.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "56.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "63.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "71.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "87.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "95.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'test_torch_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without specifying pretrained=True, we can laod the weight later\n",
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('test_torch_model.pth'))\n",
    "# set the model to eval, has effect on some modules such as\n",
    "# `Dropout`, `BatchNorm`, etc. Equal to model.train(False)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save the general checkpoint- Save model.state_dict and optimizer.state_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "Epoch = 5\n",
    "PATH = 'test_model.pth'\n",
    "Loss = 0.4\n",
    "torch.save({\n",
    "    'epoch':Epoch,\n",
    "    'model_state_dict':model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict(),\n",
    "    'loss':Loss\n",
    "}, PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load the general checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.2.weight\", \"features.2.bias\", \"features.5.weight\", \"features.5.bias\", \"features.7.weight\", \"features.7.bias\", \"features.10.weight\", \"features.10.bias\", \"features.12.weight\", \"features.12.bias\", \"features.14.weight\", \"features.14.bias\", \"features.17.weight\", \"features.17.bias\", \"features.19.weight\", \"features.19.bias\", \"features.21.weight\", \"features.21.bias\", \"features.24.weight\", \"features.24.bias\", \"features.26.weight\", \"features.26.bias\", \"features.28.weight\", \"features.28.bias\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/1274119082.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.09\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model_state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'optimizer_state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'epoch'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tfwork/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mload_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   1481\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_msgs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1482\u001B[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001B[0;32m-> 1483\u001B[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001B[0m\u001B[1;32m   1484\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_IncompatibleKeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmissing_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munexpected_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1485\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.2.weight\", \"features.2.bias\", \"features.5.weight\", \"features.5.bias\", \"features.7.weight\", \"features.7.bias\", \"features.10.weight\", \"features.10.bias\", \"features.12.weight\", \"features.12.bias\", \"features.14.weight\", \"features.14.bias\", \"features.17.weight\", \"features.17.bias\", \"features.19.weight\", \"features.19.bias\", \"features.21.weight\", \"features.21.bias\", \"features.24.weight\", \"features.24.bias\", \"features.26.weight\", \"features.26.bias\", \"features.28.weight\", \"features.28.bias\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\". "
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.09)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "# has effect on `Dropout`, `BatchNorm`, etc\n",
    "model.eval() # model.train(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.modules of Test(\n  (linear1): Linear(in_features=2, out_features=3, bias=True)\n  (lienar2): Linear(in_features=3, out_features=4, bias=True)\n  (bach_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Test(nn.Module):\n",
    "    \"\"\"UDF class of module\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 3)\n",
    "        self.lienar2 = nn.Linear(3, 4)\n",
    "        self.bach_norm = nn.BatchNorm2d(4)\n",
    "\n",
    "\n",
    "test_model = Test()\n",
    "test_model.modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('linear1', Linear(in_features=2, out_features=3, bias=True)),\n             ('lienar2', Linear(in_features=3, out_features=4, bias=True)),\n             ('bach_norm',\n              BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model._modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.5020,  0.1869],\n        [ 0.5380, -0.4350],\n        [ 0.1956, -0.4930]], requires_grad=True)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model._modules['linear1'].weight\n",
    "print(test_model._modules['linear1'].weight.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "test_model.to(torch.double)\n",
    "print(test_model._modules['linear1'].weight.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### three important attr of a model, return the attr of current model\n",
    "test_model._modules #\n",
    "test_model._parameters # empty if not init parameters\n",
    "test_model._buffers # empty if not init buffers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('linear1.weight',\n              tensor([[-0.5020,  0.1869],\n                      [ 0.5380, -0.4350],\n                      [ 0.1956, -0.4930]], dtype=torch.float64)),\n             ('linear1.bias',\n              tensor([ 0.0748,  0.4779, -0.3502], dtype=torch.float64)),\n             ('lienar2.weight',\n              tensor([[ 0.0116,  0.1853, -0.5164],\n                      [ 0.0852,  0.1703,  0.1663],\n                      [ 0.0964, -0.1226,  0.3712],\n                      [-0.4571, -0.3320,  0.2632]], dtype=torch.float64)),\n             ('lienar2.bias',\n              tensor([ 0.4797,  0.2652, -0.3681,  0.4934], dtype=torch.float64)),\n             ('bach_norm.weight',\n              tensor([1., 1., 1., 1.], dtype=torch.float64)),\n             ('bach_norm.bias', tensor([0., 0., 0., 0.], dtype=torch.float64)),\n             ('bach_norm.running_mean',\n              tensor([0., 0., 0., 0.], dtype=torch.float64)),\n             ('bach_norm.running_var',\n              tensor([1., 1., 1., 1.], dtype=torch.float64)),\n             ('bach_norm.num_batches_tracked', tensor(0))])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class VerboseExecution(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        # Register a hook for each layer\n",
    "        for name, layer in self.model.named_children():\n",
    "            layer.__name__ = name\n",
    "            layer.register_forward_hook(\n",
    "                lambda layer, _, output: print(f\"{layer.__name__}:out->{output.shape}\")\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:out->torch.Size([10, 64, 112, 112])\n",
      "bn1:out->torch.Size([10, 64, 112, 112])\n",
      "relu:out->torch.Size([10, 64, 112, 112])\n",
      "maxpool:out->torch.Size([10, 64, 56, 56])\n",
      "layer1:out->torch.Size([10, 256, 56, 56])\n",
      "layer2:out->torch.Size([10, 512, 28, 28])\n",
      "layer3:out->torch.Size([10, 1024, 14, 14])\n",
      "layer4:out->torch.Size([10, 2048, 7, 7])\n",
      "avgpool:out->torch.Size([10, 2048, 1, 1])\n",
      "fc:out->torch.Size([10, 1000])\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50()\n",
    "verbose_resnet = VerboseExecution(resnet50)\n",
    "dummy_input = torch.ones(10, 3, 224, 224)\n",
    "\n",
    "_ = verbose_resnet(dummy_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Callable\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model: nn.Module, layers: Iterable[str]):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.layers = layers # [\"layer4\", \"avgpool\"]\n",
    "        self._features = {layer: torch.empty(0) for layer in layers}\n",
    "\n",
    "        for layer_id in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_id]\n",
    "            layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
    "\n",
    "    def save_outputs_hook(self, layer_id: str) -> Callable:\n",
    "        def fn(_, __, output):\n",
    "            self._features[layer_id] = output\n",
    "        return fn\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        _ = self.model(x)\n",
    "        return self._features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")), ('features', Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")), ('features.0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.1', ReLU(inplace=True)), ('features.2', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.3', ReLU(inplace=True)), ('features.4', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('features.5', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.6', ReLU(inplace=True)), ('features.7', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.8', ReLU(inplace=True)), ('features.9', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('features.10', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.11', ReLU(inplace=True)), ('features.12', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.13', ReLU(inplace=True)), ('features.14', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.15', ReLU(inplace=True)), ('features.16', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('features.17', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.18', ReLU(inplace=True)), ('features.19', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.20', ReLU(inplace=True)), ('features.21', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.22', ReLU(inplace=True)), ('features.23', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('features.24', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.25', ReLU(inplace=True)), ('features.26', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.27', ReLU(inplace=True)), ('features.28', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('features.29', ReLU(inplace=True)), ('features.30', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('avgpool', AdaptiveAvgPool2d(output_size=(7, 7))), ('classifier', Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")), ('classifier.0', Linear(in_features=25088, out_features=4096, bias=True)), ('classifier.1', ReLU(inplace=True)), ('classifier.2', Dropout(p=0.5, inplace=False)), ('classifier.3', Linear(in_features=4096, out_features=4096, bias=True)), ('classifier.4', ReLU(inplace=True)), ('classifier.5', Dropout(p=0.5, inplace=False)), ('classifier.6', Linear(in_features=4096, out_features=1000, bias=True))]\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16()\n",
    "print([component for component in vgg16.named_modules()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer4': torch.Size([10, 2048, 7, 7]), 'avgpool': torch.Size([10, 2048, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "resnet50.named_modules\n",
    "resnet_features = FeatureExtractor(models.resnet50(), layers=[\"layer4\", \"avgpool\"])\n",
    "features = resnet_features(dummy_input)\n",
    "\n",
    "print({name: output.shape for name, output in features.items()})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getStat(train_data):\n",
    "    '''\n",
    "    Compute mean and variance for training data\n",
    "    :param train_data: è‡ªå®šä¹‰ç±»Dataset(æˆ–ImageFolderå³å¯)\n",
    "    :return: (mean, std)\n",
    "    '''\n",
    "    print('Compute mean and variance for training data.')\n",
    "    print(len(train_data))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=1, shuffle=False, num_workers=0,\n",
    "        pin_memory=True)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    for X, _ in train_loader:\n",
    "        for d in range(3):\n",
    "            mean[d] += X[:, d, :, :].mean()\n",
    "            std[d] += X[:, d, :, :].std()\n",
    "    mean.div_(len(train_data))\n",
    "    std.div_(len(train_data))\n",
    "    return list(mean.numpy()), list(std.numpy())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=r'/home/zhou/datasets', transform=None)\n",
    "    print(getStat(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1->Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "bn1->BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu->ReLU(inplace=True)\n",
      "maxpool->MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "*****0*****Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")*****\n",
      "*****1*****Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")*****\n",
      "*****2*****Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")*****\n",
      "layer1->Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer2->Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer3->Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer4->Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "avgpool->AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "fc->Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, net_module in resnet50._modules.items():\n",
    "    if name == 'layer1':\n",
    "        for name1, net_module1 in net_module._modules.items():\n",
    "            print(f'*****{name1}*****{net_module1 }*****')\n",
    "    print(f'{name}->{net_module}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace=True)\n",
      "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace=True)\n",
      "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace=True)\n",
      "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU(inplace=True)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") ***************\n",
      "***************\n",
      "\n",
      "AdaptiveAvgPool2d(output_size=(7, 7)) ***************\n",
      "***************\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ") ***************\n",
      "***************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg11()\n",
    "for sub_module in vgg.children():\n",
    "    print(sub_module,'***************\\n***************\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = nn.Sequential(*list(vgg.children())[:-1])\n",
    "print(new_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__dlpack__', '__dlpack_device__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__torch_function__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_conj', '_conj_physical', '_dimI', '_dimV', '_fix_weakref', '_grad', '_grad_fn', '_indices', '_is_view', '_make_subclass', '_neg_view', '_nnz', '_python_dispatch', '_reduce_ex_internal', '_update_names', '_values', '_version', 'abs', 'abs_', 'absolute', 'absolute_', 'acos', 'acos_', 'acosh', 'acosh_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'align_as', 'align_to', 'all', 'allclose', 'amax', 'amin', 'aminmax', 'angle', 'any', 'apply_', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan_', 'arctanh', 'arctanh_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'as_subclass', 'asin', 'asin_', 'asinh', 'asinh_', 'atan', 'atan2', 'atan2_', 'atan_', 'atanh', 'atanh_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bfloat16', 'bincount', 'bitwise_and', 'bitwise_and_', 'bitwise_left_shift', 'bitwise_left_shift_', 'bitwise_not', 'bitwise_not_', 'bitwise_or', 'bitwise_or_', 'bitwise_right_shift', 'bitwise_right_shift_', 'bitwise_xor', 'bitwise_xor_', 'bmm', 'bool', 'broadcast_to', 'byte', 'cauchy_', 'cdouble', 'ceil', 'ceil_', 'cfloat', 'char', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clip', 'clip_', 'clone', 'coalesce', 'col_indices', 'conj', 'conj_physical', 'conj_physical_', 'contiguous', 'copy_', 'copysign', 'copysign_', 'corrcoef', 'cos', 'cos_', 'cosh', 'cosh_', 'count_nonzero', 'cov', 'cpu', 'cross', 'crow_indices', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumprod_', 'cumsum', 'cumsum_', 'data', 'data_ptr', 'deg2rad', 'deg2rad_', 'dense_dim', 'dequantize', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'diff', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'divide', 'divide_', 'dot', 'double', 'dsplit', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp2', 'exp2_', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fill_', 'fill_diagonal_', 'fix', 'fix_', 'flatten', 'flip', 'fliplr', 'flipud', 'float', 'float_power', 'float_power_', 'floor', 'floor_', 'floor_divide', 'floor_divide_', 'fmax', 'fmin', 'fmod', 'fmod_', 'frac', 'frac_', 'frexp', 'gather', 'gcd', 'gcd_', 'ge', 'ge_', 'geometric_', 'geqrf', 'ger', 'get_device', 'grad', 'grad_fn', 'greater', 'greater_', 'greater_equal', 'greater_equal_', 'gt', 'gt_', 'half', 'hardshrink', 'has_names', 'heaviside', 'heaviside_', 'histc', 'histogram', 'hsplit', 'hypot', 'hypot_', 'i0', 'i0_', 'igamma', 'igamma_', 'igammac', 'igammac_', 'imag', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'inner', 'int', 'int_repr', 'inverse', 'is_coalesced', 'is_complex', 'is_conj', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_inference', 'is_leaf', 'is_meta', 'is_mkldnn', 'is_mlc', 'is_neg', 'is_nonzero', 'is_ort', 'is_pinned', 'is_quantized', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'is_sparse_csr', 'is_vulkan', 'is_xpu', 'isclose', 'isfinite', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'item', 'kron', 'kthvalue', 'layout', 'lcm', 'lcm_', 'ldexp', 'ldexp_', 'le', 'le_', 'lerp', 'lerp_', 'less', 'less_', 'less_equal', 'less_equal_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_and_', 'logical_not', 'logical_not_', 'logical_or', 'logical_or_', 'logical_xor', 'logical_xor_', 'logit', 'logit_', 'logsumexp', 'long', 'lstsq', 'lt', 'lt_', 'lu', 'lu_solve', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_exp', 'matrix_power', 'max', 'maximum', 'mean', 'median', 'min', 'minimum', 'mm', 'mode', 'moveaxis', 'movedim', 'msort', 'mul', 'mul_', 'multinomial', 'multiply', 'multiply_', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'names', 'nan_to_num', 'nan_to_num_', 'nanmean', 'nanmedian', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'ndim', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'negative', 'negative_', 'nelement', 'new', 'new_empty', 'new_empty_strided', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nextafter', 'nextafter_', 'nonzero', 'norm', 'normal_', 'not_equal', 'not_equal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'outer', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'positive', 'pow', 'pow_', 'prelu', 'prod', 'put', 'put_', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qr', 'qscheme', 'quantile', 'rad2deg', 'rad2deg_', 'random_', 'ravel', 'real', 'reciprocal', 'reciprocal_', 'record_stream', 'refine_names', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'rename', 'rename_', 'renorm', 'renorm_', 'repeat', 'repeat_interleave', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'resolve_conj', 'resolve_neg', 'retain_grad', 'retains_grad', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'sgn', 'sgn_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'signbit', 'sin', 'sin_', 'sinc', 'sinc_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'subtract', 'subtract_', 'sum', 'sum_to_size', 'svd', 'swapaxes', 'swapaxes_', 'swapdims', 'swapdims_', 'symeig', 't', 't_', 'take', 'take_along_dim', 'tan', 'tan_', 'tanh', 'tanh_', 'tensor_split', 'tile', 'to', 'to_dense', 'to_mkldnn', 'to_sparse', 'to_sparse_csr', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'triangular_solve', 'tril', 'tril_', 'triu', 'triu_', 'true_divide', 'true_divide_', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unflatten', 'unfold', 'uniform_', 'unique', 'unique_consecutive', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'vdot', 'view', 'view_as', 'vsplit', 'where', 'xlogy', 'xlogy_', 'xpu', 'zero_']\n"
     ]
    }
   ],
   "source": [
    "a_tensor = torch.ones(2,3)\n",
    "print(a_tensor.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.009)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda e:(e-100)**2/100**2, last_epoch=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.optim.lr_scheduler.LambdaLR\n",
    "torch.nn.functional\n",
    "torch.autograd.function\n",
    "torch.autograd.grad_mode\n",
    "torch.autograd.functional.jacobian\n",
    "torch.nn.Conv2d\n",
    "a_tensor.backward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/1543850368.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequires_grad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;31m# use apply method to call the UDF, forward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mExp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mret\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m#[2.7183] grad_fn=<ExpBackward>\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/1543850368.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(ctx, i)\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/1543850368.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(ctx, i)\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m             \u001B[0mmain_debugger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class Exp(torch.autograd.Function):     # compute e^x of a layer\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i.exp()\n",
    "        return result\n",
    "\n",
    "@staticmethod\n",
    "def backward(ctx, grad_output):\n",
    "    # take out info saved in forward()\n",
    "    result, = ctx.saved_tensors\n",
    "    # compute grad\n",
    "    return grad_output * result\n",
    "\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "# use apply method to call the UDF, forward\n",
    "ret = Exp.apply(x)\n",
    "print(ret) #[2.7183] grad_fn=<ExpBackward>\n",
    "ret.backward()\n",
    "print(x.grad)   # tensor([2.7183])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id a:140521811550032, id b:140521811549680\n"
     ]
    }
   ],
   "source": [
    "a = 257\n",
    "b = 257\n",
    "print(f'id a:{id(a)}, id b:{id(b)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id a:140521532307824, id b:140521801289968\n"
     ]
    }
   ],
   "source": [
    "str_a = 'a'\n",
    "str_b = 'b'\n",
    "print(f'id a:{id(str_a)}, id b:{id(str_b)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id('aa'*2) == id('a'*4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def romanToInt(self, s: str) -> int:\n",
    "\n",
    "        def sumUp(data):\n",
    "            digit_map = {'I':1, 'V':5,'X':10, 'L':50, 'C':100, 'D':500, 'M':1000}\n",
    "            res = 0\n",
    "            for char in data:\n",
    "                num = digit_map[char]\n",
    "                res += num\n",
    "            return res\n",
    "\n",
    "        data = list(s)\n",
    "        return sumUp(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/1629614679.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mSolution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mromanToInt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"MCMXCIV\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/2996487084.py\u001B[0m in \u001B[0;36mromanToInt\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msumUp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/2996487084.py\u001B[0m in \u001B[0;36mromanToInt\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msumUp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m             \u001B[0mmain_debugger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "Solution().romanToInt(\"MCMXCIV\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "['I', 'I', 'I']"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"III\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "model_a = nn.Sequential(\n",
    "    nn.Conv2d(1,20,5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20,64,5),\n",
    "    nn.ReLU() )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "model_b = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(1,20,5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(20,64,5)),\n",
    "    ('relu2', nn.ReLU()) ]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function timer.<locals>.wrapper at 0x7fcda97d58c0>\n"
     ]
    }
   ],
   "source": [
    "def timer(func):\n",
    "    import time\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        time.sleep(1)\n",
    "        long = time.time() - start\n",
    "        print(f'it takes {long} seconds')\n",
    "    print(wrapper)\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def add(a, b):\n",
    "    return a + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the repeat\n",
      "enter my_decorator\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/3960800705.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m    \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mgreet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'hello'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/3960800705.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      4\u001B[0m        \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'enter my_decorator'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m        \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m            \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m                \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'wrapper of decorator'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m                \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/n7/d0br9h110b72gtkkxx7bz0980000gn/T/ipykernel_8922/3960800705.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      4\u001B[0m        \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'enter my_decorator'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m        \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m            \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m                \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'wrapper of decorator'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m                \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    " def repeat(num):\n",
    "    print('enter the repeat')\n",
    "    def my_decorator(func):\n",
    "        print('enter my_decorator')\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for i in range(num):\n",
    "                print('wrapper of decorator')\n",
    "                func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return my_decorator\n",
    "\n",
    "@repeat(3)\n",
    "def greet(message):\n",
    "    print(message)\n",
    "\n",
    "greet('hello')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter test1\n",
      "enter test2\n",
      "wrapper2, before test2 ...\n",
      "wrapper1, before test1 ...\n",
      "execute original function 3\n",
      "wrapper1, after test1 ...\n",
      "wrapper2, after test2 ...\n"
     ]
    }
   ],
   "source": [
    "def test1(func):\n",
    "    print(\"enter test1\")\n",
    "\n",
    "    def wrapper1(*args, **kwargs):\n",
    "        print('wrapper1, before test1 ...')\n",
    "        func(*args, **kwargs)\n",
    "        print('wrapper1, after test1 ...')\n",
    "    return wrapper1 #è¿”å›žå†…å±‚å‡½æ•°çš„å¼•ç”¨\n",
    "\n",
    "def test2(func):\n",
    "    print(\"%s\" %(\"enter test2\"))\n",
    "\n",
    "    def wrapper2(*args, **kwargs):\n",
    "        print('wrapper2, before test2 ...')\n",
    "        func(*args, **kwargs)\n",
    "        print('wrapper2, after test2 ...')\n",
    "    return wrapper2 #è¿”å›žå†…å±‚å‡½æ•°çš„å¼•ç”¨\n",
    "\n",
    "@test2\n",
    "@test1\n",
    "def add(a, b):\n",
    "    print('execute original function', a+b)\n",
    "\n",
    "add(1, 2) #æ­£å¸¸è°ƒç”¨add"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_37_64.pyx\", line 1035, in _pydevd_bundle.pydevd_cython_darwin_37_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 144, in cmd_step_over\n",
      "    if _is_inside_jupyter_cell(frame, pydb):\n",
      "  File \"/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 209, in _is_inside_jupyter_cell\n",
      "    if is_cell_filename(filename):\n",
      "  File \"/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 220, in is_cell_filename\n",
      "    ipython_shell = get_ipython()\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "bb class Count:\n",
    "    def __init__(self, func):\n",
    "        self.func=func\n",
    "        self.num_calls=0\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.num_calls +=1\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "@Count\n",
    "def example():\n",
    "    print('hello')\n",
    "\n",
    "example()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoration is here\n",
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "class logger(object): # a class decorator with arguments\n",
    "    def __init__(self, level='INFO'):\n",
    "        self.level = level\n",
    "    def __call__(self, func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            print('decoration is here')\n",
    "            func(*args, **kwargs)\n",
    "        return wrapper\n",
    "@logger(level='WARNING')\n",
    "def say(message):\n",
    "    print(message)\n",
    "say('hello, world!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for 2 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "class DelayFunc:\n",
    "    def __init__(self, duration, func):\n",
    "        self.duration = duration\n",
    "        self.func = func\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print(f'waiting for {self.duration} seconds')\n",
    "        time.sleep\n",
    "        return self.func(*args, **kwargs)\n",
    "    @property\n",
    "    def eager_call(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "def delay(duration):\n",
    "    return functools.partial(DelayFunc, duration)\n",
    "\n",
    "@delay(duration=2)\n",
    "def add(a,b):\n",
    "    return a+b\n",
    "add(2, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "import functools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "def say_hello(self):\n",
    "    print('hello')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "class BaseClass:\n",
    "    def talk(self):\n",
    "        print('hello')\n",
    "def say(self):\n",
    "    print('hi, there')\n",
    "\n",
    "    # use type to create User class\n",
    "User = type('User', (BaseClass, ), {'name':'user', 'say':say_hello})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "User().say()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    " class Fab(object):\n",
    "\n",
    "    def __init__(self, max):\n",
    "        self.max = max\n",
    "        self.n, self.a, self.b = 0, 0, 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        if self.n < self.max:\n",
    "            r = self.b\n",
    "            self.a, self.b = self.b, self.a + self.b\n",
    "            self.n = self.n + 1\n",
    "            return r\n",
    "        raise StopIteration()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "fab = Fab(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class dict: dict_keys(['__module__', 'name', 'unique', '__init__', 'eat', 'sleep', '__dict__', '__weakref__', '__doc__'])\n",
      "inst dict: dict_keys(['name', 'age', 'weight'])\n",
      "dict_keys(['age'])\n"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    name = 'è€è™Ž'\n",
    "    unique = 0\n",
    "    def __init__(self, name='è€è™Ž', age=5):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.weight = 200\n",
    "\n",
    "    def eat(self):\n",
    "        self.height = 100\n",
    "        return 'æˆ‘éœ€è¦åƒä¸œè¥¿ï¼'\n",
    "\n",
    "    @classmethod\n",
    "    def sleep(cls):\n",
    "        return 'æˆ‘éœ€è¦ç¡è§‰'\n",
    "\n",
    "class Dog(Animal):\n",
    "\n",
    "    def __init__(self, age):\n",
    "        self.age = age\n",
    "\n",
    "a = Animal()\n",
    "d = Dog(8)\n",
    "\n",
    "# dict_keys(['__module__', 'name', 'unique', '__init__', 'eat', 'sleep', '__dict__', '__weakref__', '__doc__'])\n",
    "print('class dict:',Animal.__dict__.keys())\n",
    "print('inst dict:',a.__dict__.keys())\n",
    "print(d.__dict__.keys())     # dict_keys(['age'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor init: init\n",
      "Assigning value: instance\n",
      "Getting value\n",
      "2: descriptor returned value\n",
      "Assigning value: test\n",
      "Getting value\n",
      "3: descriptor returned value\n"
     ]
    }
   ],
   "source": [
    "class Descriptor:\n",
    "    def __init__(self, var1):\n",
    "        print(f\"descriptor init: {var1}\")\n",
    "        self.var1 = var1\n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        \"\"\"\"\"\"\n",
    "        print(f\"Assigning value: {value}\")\n",
    "\n",
    "    def __get__(self, instance, owner=None):\n",
    "        \"\"\"\"\"\"\n",
    "        print('Getting value')\n",
    "        return \"descriptor returned value\"\n",
    "\n",
    "\n",
    "class Person:\n",
    "\n",
    "    foo = Descriptor(\"init\")\n",
    "    def __init__(self, value):\n",
    "        self.foo = value\n",
    "\n",
    "person = Person('instance') # descriptor init: init, Assigning instance\n",
    "print(\"2:\", person.foo)      # Getting value, 2 descriptor returned value\n",
    "person.foo ='test'          # Assigning test\n",
    "print(\"3:\", person.foo)      # Getting value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "4\n",
      "********************\n",
      "res is: None\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print(\"starting...\")\n",
    "    while True:\n",
    "        res = yield 4\n",
    "        print(\"res is:\",res)\n",
    "g = foo()\n",
    "print(next(g))\n",
    "print(\"*\"*20)\n",
    "print(next(g))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "jupyter_env",
   "language": "python",
   "display_name": "Python3 (py3env)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}